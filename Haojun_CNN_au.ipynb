{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using CNN\n",
    "\n",
    "Here we are attempting to train a small Convolution Neural Network to see if the neural network can extract features that can help us improve our classical algorithms.\n",
    "\n",
    "One thing we are concerned about is the fact that classical algorithms cannot perform better tha CNNs. However, we aim to improve classical algorithms because they can run at a much faster speed. So if our CNN feature extractor paired with classical algorithms can perform just as well as original CNNs, it is promising that we can apply this to large datasets that CNN will take too long to run. One other thing is we can run classical algorithms in real time, meaning we can classify music much faster in real time than passing it through a CNN\n",
    "\n",
    "This file will contain all code to extract features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "First we will load out date into the notebook so we can process them easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data_mat/X2.npy')\n",
    "Y = np.load('data_mat/Y2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training X shape is (500, 20, 1290)\n",
      "training Y shape is (500, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"training X shape is {0}\".format(X.shape))\n",
    "print(\"training Y shape is {0}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the training set to the model easier, we will transform our data and split them so they can be fed into the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2085a6f3b38>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0][:, :100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training X shape is (500, 1290, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2087273e5f8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X2 = np.transpose(X, (0, 2, 1))\n",
    "print(\"training X shape is {0}\".format(X2.shape))\n",
    "plt.imshow(X2[0][:100, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1290, 20) (100, 1290, 20) (400, 5) (100, 5)\n"
     ]
    }
   ],
   "source": [
    "inds = np.arange(X2.shape[0])\n",
    "np.random.shuffle(inds)\n",
    "X_train, X_test, Y_train, Y_test = ms.train_test_split(X2[inds], Y[inds], test_size=0.2, random_state=123)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN modeling\n",
    "\n",
    "Here we will use a 1D convolution layer, followed by standard pool, relu layers, followed by dense layers and then a softmax unit for output prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape):\n",
    "    X_inputs = keras.layers.Input(input_shape)\n",
    "    X = X_inputs\n",
    "    print(X.shape)\n",
    "    X = keras.layers.Conv1D(filters=4, kernel_size=32, dilation_rate=8,\n",
    "                            padding='same', data_format=\"channels_last\")(X)\n",
    "    print(X.shape)\n",
    "    X = keras.layers.Dropout(0.5)(X)    \n",
    "    X = keras.layers.AveragePooling1D(pool_size=32)(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 2)(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    print(X.shape)\n",
    "#     X = keras.layers.Dropout(0.7)(X)    \n",
    "    X = keras.layers.Conv1D(filters=16, kernel_size=16, dilation_rate=2, padding='valid', data_format=\"channels_last\")(X)\n",
    "    X = keras.layers.Dropout(0.5)(X)    \n",
    "    X = keras.layers.AveragePooling1D(pool_size=4)(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 2)(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    print(X.shape)\n",
    "#     X = keras.layers.Dropout(0.5)(X)    \n",
    "#     X = keras.layers.Conv1D(filters=30, kernel_size=4, dilation_rate=1, padding='valid', data_format=\"channels_last\")(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X)    \n",
    "#     X = keras.layers.AveragePooling1D(pool_size=4)(X)\n",
    "#     X = keras.layers.BatchNormalization(axis = 2)(X)\n",
    "#     X = keras.layers.Activation('relu')(X)\n",
    "# #     X = keras.layers.Dropout(0.5)(X)    \n",
    "#     print(X.shape)\n",
    "#     X = keras.layers.Conv1D(filters=8, kernel_size=2, dilation_rate=2, padding='valid', data_format=\"channels_last\")(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X)    \n",
    "#     X = keras.layers.MaxPooling1D(pool_size=2)(X)\n",
    "#     X = keras.layers.BatchNormalization(axis = 2)(X)\n",
    "#     X = keras.layers.Activation('relu')(X)\n",
    "# #     X = keras.layers.Dropout(0.5)(X)    \n",
    "#     print(X.shape)\n",
    "    \n",
    "    X = keras.layers.Flatten()(X)\n",
    "#     X = keras.layers.Dense(20, activation='sigmoid')(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X)    \n",
    "# #     X = keras.layers.Dense(35, activation='sigmoid')(X)\n",
    "#     X = keras.layers.Dense(10, activation='sigmoid')(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X)    \n",
    "#     X = keras.layers.Dense(30, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dropout(0.5)(X)    \n",
    "    X = keras.layers.Dense(5, activation='softmax')(X)\n",
    "    print(X.shape)\n",
    "    \n",
    "    model = keras.models.Model(inputs=X_inputs, outputs=X, name='cnn')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1290, 20)\n",
      "(?, 1290, 4)\n",
      "(?, 40, 4)\n",
      "(?, 2, 16)\n",
      "(?, 5)\n"
     ]
    }
   ],
   "source": [
    "m = model(X2.shape[1:])\n",
    "# optimizer = keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999)\n",
    "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1290, 20)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1290, 4)           2564      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1290, 4)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_9 (Average (None, 40, 4)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 40, 4)             16        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 40, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 10, 16)            1040      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 10, 16)            0         \n",
      "_________________________________________________________________\n",
      "average_pooling1d_10 (Averag (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,849\n",
      "Trainable params: 3,809\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "400/400 [==============================] - 1s 3ms/step - loss: 2.1578 - categorical_accuracy: 0.1975\n",
      "Epoch 2/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.9353 - categorical_accuracy: 0.2425\n",
      "Epoch 3/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.6856 - categorical_accuracy: 0.3075\n",
      "Epoch 4/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.6259 - categorical_accuracy: 0.3025\n",
      "Epoch 5/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.5034 - categorical_accuracy: 0.3150\n",
      "Epoch 6/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.4449 - categorical_accuracy: 0.3600\n",
      "Epoch 7/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.4094 - categorical_accuracy: 0.3825\n",
      "Epoch 8/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.3688 - categorical_accuracy: 0.4325\n",
      "Epoch 9/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.4094 - categorical_accuracy: 0.4050\n",
      "Epoch 10/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.3131 - categorical_accuracy: 0.4600\n",
      "Epoch 11/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.2800 - categorical_accuracy: 0.4625\n",
      "Epoch 12/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.3072 - categorical_accuracy: 0.4375\n",
      "Epoch 13/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.1887 - categorical_accuracy: 0.5300\n",
      "Epoch 14/150\n",
      "400/400 [==============================] - 0s 977us/step - loss: 1.1757 - categorical_accuracy: 0.5000\n",
      "Epoch 15/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.1556 - categorical_accuracy: 0.5425\n",
      "Epoch 16/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.2337 - categorical_accuracy: 0.4975\n",
      "Epoch 17/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.1343 - categorical_accuracy: 0.5350\n",
      "Epoch 18/150\n",
      "400/400 [==============================] - 0s 977us/step - loss: 1.1715 - categorical_accuracy: 0.5175\n",
      "Epoch 19/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.1077 - categorical_accuracy: 0.5075\n",
      "Epoch 20/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.0925 - categorical_accuracy: 0.5750\n",
      "Epoch 21/150\n",
      "400/400 [==============================] - 0s 977us/step - loss: 1.0296 - categorical_accuracy: 0.5800\n",
      "Epoch 22/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.0773 - categorical_accuracy: 0.5600\n",
      "Epoch 23/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 1.0971 - categorical_accuracy: 0.5550\n",
      "Epoch 24/150\n",
      "400/400 [==============================] - 0s 977us/step - loss: 1.0476 - categorical_accuracy: 0.5875\n",
      "Epoch 25/150\n",
      "400/400 [==============================] - 0s 991us/step - loss: 1.0117 - categorical_accuracy: 0.6275\n",
      "Epoch 26/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.9840 - categorical_accuracy: 0.6125\n",
      "Epoch 27/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.9702 - categorical_accuracy: 0.6225\n",
      "Epoch 28/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.9473 - categorical_accuracy: 0.6300\n",
      "Epoch 29/150\n",
      "400/400 [==============================] - 0s 977us/step - loss: 0.9325 - categorical_accuracy: 0.6425\n",
      "Epoch 30/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.9843 - categorical_accuracy: 0.6275\n",
      "Epoch 31/150\n",
      "400/400 [==============================] - 0s 977us/step - loss: 0.9358 - categorical_accuracy: 0.6525\n",
      "Epoch 32/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.9050 - categorical_accuracy: 0.6600\n",
      "Epoch 33/150\n",
      "400/400 [==============================] - 0s 977us/step - loss: 0.9212 - categorical_accuracy: 0.6625\n",
      "Epoch 34/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.9225 - categorical_accuracy: 0.6425\n",
      "Epoch 35/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.9244 - categorical_accuracy: 0.6300\n",
      "Epoch 36/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8791 - categorical_accuracy: 0.6600\n",
      "Epoch 37/150\n",
      "400/400 [==============================] - 0s 995us/step - loss: 0.8659 - categorical_accuracy: 0.6600\n",
      "Epoch 38/150\n",
      "400/400 [==============================] - 0s 979us/step - loss: 0.9051 - categorical_accuracy: 0.6475\n",
      "Epoch 39/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8273 - categorical_accuracy: 0.6850\n",
      "Epoch 40/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8881 - categorical_accuracy: 0.6825\n",
      "Epoch 41/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8527 - categorical_accuracy: 0.6750\n",
      "Epoch 42/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.9297 - categorical_accuracy: 0.6625\n",
      "Epoch 43/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8395 - categorical_accuracy: 0.6875\n",
      "Epoch 44/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8651 - categorical_accuracy: 0.6525\n",
      "Epoch 45/150\n",
      "400/400 [==============================] - 0s 977us/step - loss: 0.8786 - categorical_accuracy: 0.6775\n",
      "Epoch 46/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8067 - categorical_accuracy: 0.6700\n",
      "Epoch 47/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8338 - categorical_accuracy: 0.6950\n",
      "Epoch 48/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8120 - categorical_accuracy: 0.6925\n",
      "Epoch 49/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8272 - categorical_accuracy: 0.6950\n",
      "Epoch 50/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8086 - categorical_accuracy: 0.6825\n",
      "Epoch 51/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8446 - categorical_accuracy: 0.6675\n",
      "Epoch 52/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8088 - categorical_accuracy: 0.6675\n",
      "Epoch 53/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.8130 - categorical_accuracy: 0.6775\n",
      "Epoch 54/150\n",
      "400/400 [==============================] - 0s 991us/step - loss: 0.8369 - categorical_accuracy: 0.6775\n",
      "Epoch 55/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7785 - categorical_accuracy: 0.7050\n",
      "Epoch 56/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7737 - categorical_accuracy: 0.7150\n",
      "Epoch 57/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7862 - categorical_accuracy: 0.7000\n",
      "Epoch 58/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7883 - categorical_accuracy: 0.7200\n",
      "Epoch 59/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7990 - categorical_accuracy: 0.7025\n",
      "Epoch 60/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7732 - categorical_accuracy: 0.7075\n",
      "Epoch 61/150\n",
      "400/400 [==============================] - 0s 994us/step - loss: 0.8259 - categorical_accuracy: 0.6775\n",
      "Epoch 62/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7867 - categorical_accuracy: 0.7025\n",
      "Epoch 63/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7868 - categorical_accuracy: 0.6950\n",
      "Epoch 64/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7682 - categorical_accuracy: 0.6975\n",
      "Epoch 65/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7226 - categorical_accuracy: 0.7325\n",
      "Epoch 66/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7599 - categorical_accuracy: 0.6975\n",
      "Epoch 67/150\n",
      "400/400 [==============================] - 0s 999us/step - loss: 0.7136 - categorical_accuracy: 0.7425\n",
      "Epoch 68/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7580 - categorical_accuracy: 0.7200\n",
      "Epoch 69/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7923 - categorical_accuracy: 0.7025\n",
      "Epoch 70/150\n",
      "400/400 [==============================] - 0s 993us/step - loss: 0.7569 - categorical_accuracy: 0.7375\n",
      "Epoch 71/150\n",
      "400/400 [==============================] - 0s 994us/step - loss: 0.7365 - categorical_accuracy: 0.7250\n",
      "Epoch 72/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7759 - categorical_accuracy: 0.7075\n",
      "Epoch 73/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7298 - categorical_accuracy: 0.7575\n",
      "Epoch 74/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7822 - categorical_accuracy: 0.7100\n",
      "Epoch 75/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7739 - categorical_accuracy: 0.7175\n",
      "Epoch 76/150\n",
      "400/400 [==============================] - 0s 981us/step - loss: 0.7335 - categorical_accuracy: 0.7400\n",
      "Epoch 77/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7492 - categorical_accuracy: 0.7525\n",
      "Epoch 78/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6984 - categorical_accuracy: 0.7350\n",
      "Epoch 79/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7409 - categorical_accuracy: 0.7300\n",
      "Epoch 80/150\n",
      "400/400 [==============================] - 0s 998us/step - loss: 0.6962 - categorical_accuracy: 0.7650\n",
      "Epoch 81/150\n",
      "400/400 [==============================] - 0s 992us/step - loss: 0.6832 - categorical_accuracy: 0.7225\n",
      "Epoch 82/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7378 - categorical_accuracy: 0.7350\n",
      "Epoch 83/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6969 - categorical_accuracy: 0.7400\n",
      "Epoch 84/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7119 - categorical_accuracy: 0.7225\n",
      "Epoch 85/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7120 - categorical_accuracy: 0.7225\n",
      "Epoch 86/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7275 - categorical_accuracy: 0.7375\n",
      "Epoch 87/150\n",
      "400/400 [==============================] - 0s 995us/step - loss: 0.6740 - categorical_accuracy: 0.7650\n",
      "Epoch 88/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7289 - categorical_accuracy: 0.7275\n",
      "Epoch 89/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7190 - categorical_accuracy: 0.7350\n",
      "Epoch 90/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7158 - categorical_accuracy: 0.7200\n",
      "Epoch 91/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6535 - categorical_accuracy: 0.7700\n",
      "Epoch 92/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7052 - categorical_accuracy: 0.7350\n",
      "Epoch 93/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7015 - categorical_accuracy: 0.7250\n",
      "Epoch 94/150\n",
      "400/400 [==============================] - 0s 977us/step - loss: 0.6662 - categorical_accuracy: 0.7650\n",
      "Epoch 95/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7281 - categorical_accuracy: 0.7225\n",
      "Epoch 96/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7003 - categorical_accuracy: 0.7175\n",
      "Epoch 97/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7015 - categorical_accuracy: 0.7600\n",
      "Epoch 98/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7002 - categorical_accuracy: 0.7300\n",
      "Epoch 99/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6491 - categorical_accuracy: 0.7675\n",
      "Epoch 100/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7518 - categorical_accuracy: 0.7175\n",
      "Epoch 101/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6670 - categorical_accuracy: 0.7450\n",
      "Epoch 102/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6636 - categorical_accuracy: 0.7425\n",
      "Epoch 103/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6515 - categorical_accuracy: 0.7675\n",
      "Epoch 104/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6422 - categorical_accuracy: 0.7750\n",
      "Epoch 105/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6985 - categorical_accuracy: 0.7775\n",
      "Epoch 106/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6945 - categorical_accuracy: 0.7350\n",
      "Epoch 107/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6863 - categorical_accuracy: 0.7575\n",
      "Epoch 108/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6923 - categorical_accuracy: 0.7200\n",
      "Epoch 109/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7015 - categorical_accuracy: 0.7375\n",
      "Epoch 110/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6652 - categorical_accuracy: 0.7650\n",
      "Epoch 111/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6816 - categorical_accuracy: 0.7475\n",
      "Epoch 112/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7009 - categorical_accuracy: 0.7400\n",
      "Epoch 113/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6889 - categorical_accuracy: 0.7450\n",
      "Epoch 114/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6669 - categorical_accuracy: 0.7550\n",
      "Epoch 115/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6612 - categorical_accuracy: 0.7625: 0s - loss: 0.6572 - categorical_accuracy: 0.76\n",
      "Epoch 116/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6784 - categorical_accuracy: 0.7375\n",
      "Epoch 117/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6764 - categorical_accuracy: 0.7350\n",
      "Epoch 118/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6758 - categorical_accuracy: 0.7525\n",
      "Epoch 119/150\n",
      "400/400 [==============================] - 0s 993us/step - loss: 0.6774 - categorical_accuracy: 0.7725\n",
      "Epoch 120/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6230 - categorical_accuracy: 0.7625\n",
      "Epoch 121/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6724 - categorical_accuracy: 0.7600\n",
      "Epoch 122/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6588 - categorical_accuracy: 0.7525\n",
      "Epoch 123/150\n",
      "400/400 [==============================] - 0s 997us/step - loss: 0.6043 - categorical_accuracy: 0.7800\n",
      "Epoch 124/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6759 - categorical_accuracy: 0.7400\n",
      "Epoch 125/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7132 - categorical_accuracy: 0.7425\n",
      "Epoch 126/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7108 - categorical_accuracy: 0.7325\n",
      "Epoch 127/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6561 - categorical_accuracy: 0.7425\n",
      "Epoch 128/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6617 - categorical_accuracy: 0.7725\n",
      "Epoch 129/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.7031 - categorical_accuracy: 0.7425\n",
      "Epoch 130/150\n",
      "400/400 [==============================] - 0s 996us/step - loss: 0.6693 - categorical_accuracy: 0.7450\n",
      "Epoch 131/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6817 - categorical_accuracy: 0.7350\n",
      "Epoch 132/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6305 - categorical_accuracy: 0.7750\n",
      "Epoch 133/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6558 - categorical_accuracy: 0.7575\n",
      "Epoch 134/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6435 - categorical_accuracy: 0.7550\n",
      "Epoch 135/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6010 - categorical_accuracy: 0.7925\n",
      "Epoch 136/150\n",
      "400/400 [==============================] - 0s 998us/step - loss: 0.6175 - categorical_accuracy: 0.7625\n",
      "Epoch 137/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6837 - categorical_accuracy: 0.7675\n",
      "Epoch 138/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6411 - categorical_accuracy: 0.7750\n",
      "Epoch 139/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6368 - categorical_accuracy: 0.7525\n",
      "Epoch 140/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6350 - categorical_accuracy: 0.7725\n",
      "Epoch 141/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6024 - categorical_accuracy: 0.8000\n",
      "Epoch 142/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6641 - categorical_accuracy: 0.7475\n",
      "Epoch 143/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6177 - categorical_accuracy: 0.7650\n",
      "Epoch 144/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.5801 - categorical_accuracy: 0.7675\n",
      "Epoch 145/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6076 - categorical_accuracy: 0.7900\n",
      "Epoch 146/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6656 - categorical_accuracy: 0.7350\n",
      "Epoch 147/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6562 - categorical_accuracy: 0.7475\n",
      "Epoch 148/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6203 - categorical_accuracy: 0.7800\n",
      "Epoch 149/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6271 - categorical_accuracy: 0.7425\n",
      "Epoch 150/150\n",
      "400/400 [==============================] - 0s 1ms/step - loss: 0.6229 - categorical_accuracy: 0.7575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208a9fe0048>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(X_train, Y_train, epochs=150, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step\n",
      "Loss = 0.6301189586520195\n",
      "Test Accuracy = 0.76\n"
     ]
    }
   ],
   "source": [
    "preds = m.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "Here we want to use the neural network that we trained to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x208a8ca0438>,\n",
       " <keras.layers.convolutional.Conv1D at 0x208a8ca05c0>,\n",
       " <keras.layers.core.Dropout at 0x208a8ca0a90>,\n",
       " <keras.layers.pooling.AveragePooling1D at 0x208a8c70fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x208a8c64668>,\n",
       " <keras.layers.core.Activation at 0x208a8c64908>,\n",
       " <keras.layers.convolutional.Conv1D at 0x208a8c5b0b8>,\n",
       " <keras.layers.core.Dropout at 0x208a9e04198>,\n",
       " <keras.layers.pooling.AveragePooling1D at 0x208a9e04240>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x208a9e34c18>,\n",
       " <keras.layers.core.Activation at 0x208a9e34d30>,\n",
       " <keras.layers.core.Flatten at 0x208a9eb7dd8>,\n",
       " <keras.layers.core.Dropout at 0x208a9e70ba8>,\n",
       " <keras.layers.core.Dense at 0x208a9e70d30>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = m\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Activation object at 0x00000208A8C64908> <keras.layers.core.Flatten object at 0x00000208A9EB7DD8>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[5], model.layers[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(X, model, layer_nums, batch_num):\n",
    "    \"\"\"Extract all the features by taking out the activation output of the layers specified in layer_nums\n",
    "    \n",
    "        X : the data that we are trying to extract features from\n",
    "        model: the model that we are using to extract the features\n",
    "        layer_nums: the layer number that we want to use as feature extractors\n",
    "    \"\"\"\n",
    "    outputs = [model.layers[layer].output for layer in layer_nums]\n",
    "    f = keras.backend.function([model.input, keras.backend.learning_phase()], outputs)\n",
    "    ## split up into smaller chunks\n",
    "    layer_outs = []\n",
    "    m = X.shape[0]\n",
    "    for i in range(batch_num):\n",
    "        layer_outs += [f([X[(m // batch_num * i):(m // batch_num * (i+1)), :, :], 0.])]\n",
    "    result = []\n",
    "    for i in range(len(layer_nums)):\n",
    "        layer_outs2 = []\n",
    "        for batch in range(batch_num):\n",
    "            activations = layer_outs[batch][i]\n",
    "            activations = activations.reshape(activations.shape[0], -1)\n",
    "            layer_outs2 += [activations]\n",
    "        result += [np.vstack(np.array(layer_outs2))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outs_train = extract_all_features(X_train, model, [5, 11], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outs_test = extract_all_features(X_test, model, [5, 11], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3_train, conv_2_train, conv_1_train = layer_outs_train\n",
    "conv_3_test, conv_2_test, conv_1_test = layer_outs_test\n",
    "np.savetxt('conv_3_train.txt', conv_3_train)\n",
    "np.savetxt('conv_2_train.txt', conv_2_train)\n",
    "np.savetxt('conv_1_train.txt', conv_1_train)\n",
    "np.savetxt('conv_3_test.txt', conv_3_test)\n",
    "np.savetxt('conv_2_test.txt', conv_2_test)\n",
    "np.savetxt('conv_1_test.txt', conv_1_test)\n",
    "np.savetxt('Y_train.txt', Y_train)\n",
    "np.savetxt('Y_test.txt', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
