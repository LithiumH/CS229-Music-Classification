{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as skmetrics\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 5) (100, 5)\n"
     ]
    }
   ],
   "source": [
    "Y_train_1hot = np.loadtxt('extracted/Y_train.txt')\n",
    "Y_test_1hot = np.loadtxt('extracted/Y_test.txt')\n",
    "print Y_train_1hot.shape, Y_test_1hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (100,)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.where(Y_train_1hot==1)[1]\n",
    "Y_test = np.where(Y_test_1hot==1)[1]\n",
    "print Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First** we will use the flattened matrices as feature and try different classification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 25800) (100, 25800)\n"
     ]
    }
   ],
   "source": [
    "X_flatten_train = np.load('extracted/X_train.npy').reshape(Y_train.shape[0],-1)\n",
    "X_flatten_test = np.load('extracted/X_test.npy').reshape(Y_test.shape[0],-1)\n",
    "print X_flatten_train.shape, X_flatten_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 50) (100, 50)\n"
     ]
    }
   ],
   "source": [
    "pca_conv = PCA(50)\n",
    "pca_conv.fit(X_flatten_train)\n",
    "train_pca = pca_conv.transform(X_flatten_train)\n",
    "test_pca = pca_conv.transform(X_flatten_test)\n",
    "print train_pca.shape, test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# of Misclassification: 79\n",
      "\tTrain accuracy: 1.0\n",
      "\tTest accuracy: 0.21\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='scale').fit(train_pca, Y_train)\n",
    "Y_pred = clf.predict(test_pca)\n",
    "error = sum([1 for i in range(len(Y_test)) if Y_test[i] != Y_pred[i]])\n",
    "train_error = clf.score(train_pca, Y_train)\n",
    "test_error = clf.score(test_pca, Y_test)\n",
    "\n",
    "print '\\t# of Misclassification: %s' % str(error)\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# of Misclassification: 19\n",
      "\tTrain accuracy: 0.925\n",
      "\tTest accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0, solver='newton-cg').fit(train_pca, Y_train)\n",
    "Y_pred = lr.predict(test_pca)\n",
    "Y_train_pred = lr.predict(train_pca)\n",
    "error = sum([1 for i in range(len(Y_test)) if Y_test[i] != Y_pred[i]])\n",
    "train_error = lr.score(train_pca, Y_train)\n",
    "test_error = lr.score(test_pca, Y_test)\n",
    "\n",
    "# train_error = skmetrics.precision_score(train_pca, Y_train_pred, average='micro') \n",
    "# test_error = skmetrics.precision_score(test_pca, Y_pred, average='micro') \n",
    "\n",
    "print '\\t# of Misclassification: %s' % str(error)\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.84\n",
      "\tTest accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "X_train = train_pca\n",
    "X_test = test_pca\n",
    "\n",
    "gda = LinearDiscriminantAnalysis().fit(X_train, Y_train)\n",
    "Y_pred = gda.predict(X_test)\n",
    "train_error = gda.score(X_train, Y_train)\n",
    "test_error = gda.score(X_test, Y_test)\n",
    "\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 1.0\n",
      "\tTest accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "X_train = train_pca\n",
    "X_test = test_pca\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=0).fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "train_error = clf.score(X_train, Y_train)\n",
    "test_error = clf.score(X_test, Y_test)\n",
    "\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM on the raw input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM for flattened raw matrices ...\n",
      "\t# of Misclassification: 72\n",
      "\tTrain accuracy: 1.0\n",
      "\tTest accuracy: 0.28\n"
     ]
    }
   ],
   "source": [
    "print 'Training SVM for flattened raw matrices ...'\n",
    "clf = svm.SVC(gamma='scale').fit(X_flatten_train, Y_train)\n",
    "Y_pred = clf.predict(X_flatten_test)\n",
    "error = sum([1 for i in range(len(Y_test)) if Y_test[i] != Y_pred[i]])\n",
    "train_error = clf.score(X_flatten_train, Y_train)\n",
    "test_error = clf.score(X_flatten_test, Y_test)\n",
    "\n",
    "print '\\t# of Misclassification: %s' % str(error)\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM on a hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM for conv_1 layers ...\n",
      "(400, 320)\n",
      "\t# of Misclassification: 18\n",
      "\tTrain accuracy: 0.945\n",
      "\tTest accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "print 'Training SVM for conv_1 layers ...'\n",
    "\n",
    "mat_path = 'extracted'\n",
    "name = 'conv_1'\n",
    "\n",
    "X_train_hidden1 = np.loadtxt(os.path.join(mat_path, name+'_train.txt'))\n",
    "X_test_hidden1 = np.loadtxt(os.path.join(mat_path, name+'_test.txt'))\n",
    "print X_train_hidden1.shape\n",
    "\n",
    "clf = svm.SVC(gamma='scale').fit(X_train_hidden1, Y_train)\n",
    "Y_pred = clf.predict(X_test_hidden1)\n",
    "error = sum([1 for i in range(len(Y_test)) if Y_test[i] != Y_pred[i]])\n",
    "train_error = clf.score(X_train_hidden1, Y_train)\n",
    "test_error = clf.score(X_test_hidden1, Y_test)\n",
    "\n",
    "print '\\t# of Misclassification: %s' % str(error)\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM for conv_2 ...\n",
      "(400, 48)\n",
      "\t# of Misclassification: 16\n",
      "\tTrain accuracy: 0.95\n",
      "\tTest accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "print 'Training SVM for conv_2 ...'\n",
    "\n",
    "mat_path = 'extracted'\n",
    "name = 'conv_2'\n",
    "\n",
    "X_train_hidden2 = np.loadtxt(os.path.join(mat_path, name+'_train.txt'))\n",
    "X_test_hidden2 = np.loadtxt(os.path.join(mat_path, name+'_test.txt'))\n",
    "print X_train_hidden2.shape\n",
    "\n",
    "clf = svm.SVC(gamma='scale').fit(X_train_hidden2, Y_train)\n",
    "Y_pred = clf.predict(X_test_hidden2)\n",
    "error = sum([1 for i in range(len(Y_test)) if Y_test[i] != Y_pred[i]])\n",
    "train_error = clf.score(X_train_hidden2, Y_train)\n",
    "test_error = clf.score(X_test_hidden2, Y_test)\n",
    "\n",
    "print '\\t# of Misclassification: %s' % str(error)\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression on raw input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR for flattened raw matrices ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t# of Misclassification: 23\n",
      "\tTrain accuracy: 1.0\n",
      "\tTest accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "print 'Training LR for flattened raw matrices ...' \n",
    "\n",
    "lr = LogisticRegression(random_state=0, solver='newton-cg').fit(X_flatten_train, Y_train)\n",
    "Y_pred = lr.predict(X_flatten_test)\n",
    "Y_train_pred = lr.predict(X_flatten_train)\n",
    "error = sum([1 for i in range(len(Y_test)) if Y_test[i] != Y_pred[i]])\n",
    "\n",
    "# train_error = lr.score(X_flatten_train, Y_train)\n",
    "# test_error = lr.score(X_flatten_test, Y_test)\n",
    "\n",
    "train_error = skmetrics.precision_score(Y_train, Y_train_pred, average='micro') \n",
    "test_error = skmetrics.precision_score(Y_test, Y_pred, average='micro') \n",
    "\n",
    "print '\\t# of Misclassification: %s' % str(error)\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression on hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR for hidden layer 1 ...\n",
      "\t# of Misclassification: 12\n",
      "\tTrain accuracy: 0.945\n",
      "\tTest accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "print 'Training LR for hidden layer 1 ...' \n",
    "\n",
    "lr = LogisticRegression(random_state=0, solver='newton-cg').fit(X_train_hidden1, Y_train)\n",
    "Y_pred = lr.predict(X_test_hidden1)\n",
    "Y_train_pred = lr.predict(X_train_hidden1)\n",
    "error = sum([1 for i in range(len(Y_test)) if Y_test[i] != Y_pred[i]])\n",
    "\n",
    "train_error = skmetrics.precision_score(Y_train, Y_train_pred, average='micro') \n",
    "test_error = skmetrics.precision_score(Y_test, Y_pred, average='micro') \n",
    "\n",
    "\n",
    "print '\\t# of Misclassification: %s' % str(error)\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR for hidden layer 2 ...\n",
      "\t# of Misclassification: 12\n",
      "\tTrain accuracy: 0.9875\n",
      "\tTest accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "print 'Training LR for hidden layer 2 ...' \n",
    "\n",
    "lr = LogisticRegression(random_state=0, solver='newton-cg').fit(X_train_hidden2, Y_train)\n",
    "Y_pred = lr.predict(X_test_hidden2)\n",
    "Y_train_pred = lr.predict(X_train_hidden2)\n",
    "error = sum([1 for i in range(len(Y_test)) if Y_test[i] != Y_pred[i]])\n",
    "\n",
    "train_error = skmetrics.precision_score(Y_train, Y_train_pred, average='micro') \n",
    "test_error = skmetrics.precision_score(Y_test, Y_pred, average='micro') \n",
    "\n",
    "\n",
    "print '\\t# of Misclassification: %s' % str(error)\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.xticks(list(range(5)), ['classical', 'hiphop', 'metal', 'pop', 'blues'])\n",
    "plt.yticks(list(range(5)), ['classical', 'hiphop', 'metal', 'pop', 'blues'])\n",
    "# plt.tick_params(labelsize=20)\n",
    "plt.title('Confusion matrix for Logistic Regression model')\n",
    "plt.savefig('plots/log_confusion.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GDA on raw input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 0.8875\n",
      "\tTest accuracy: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "X_train = X_flatten_train\n",
    "X_test = X_flatten_test\n",
    "\n",
    "gda = LinearDiscriminantAnalysis().fit(X_train, Y_train)\n",
    "Y_pred = gda.predict(X_test)\n",
    "train_error = gda.score(X_train, Y_train)\n",
    "test_error = gda.score(X_test, Y_test)\n",
    "\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using GDA on hidden layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GDA for conv_1 ...\n",
      "\tTrain accuracy: 0.94\n",
      "\tTest accuracy: 0.8\n",
      "Training GDA for conv_2 ...\n",
      "\tTrain accuracy: 1.0\n",
      "\tTest accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "fix = ['conv_1', 'conv_2']\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "for name in fix:\n",
    "    X_train = np.loadtxt(os.path.join(mat_path, name+'_train.txt'))\n",
    "    X_test = np.loadtxt(os.path.join(mat_path, name+'_test.txt'))\n",
    "    \n",
    "    print 'Training GDA for %s ...' % name\n",
    "    gda = LinearDiscriminantAnalysis().fit(X_train, Y_train)\n",
    "    Y_pred = gda.predict(X_test)\n",
    "    train_error = gda.score(X_train, Y_train)\n",
    "    test_error = gda.score(X_test, Y_test)\n",
    "\n",
    "    print '\\tTrain accuracy: %s' % str(train_error)\n",
    "    print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Random Forests for raw input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 1.0\n",
      "\tTest accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "X_train = X_flatten_train\n",
    "X_test = X_flatten_test\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=0).fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "train_error = clf.score(X_train, Y_train)\n",
    "test_error = clf.score(X_test, Y_test)\n",
    "\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Random Forests for hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 1.0\n",
      "\tTest accuracy: 0.87\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_hidden1\n",
    "X_test = X_test_hidden1\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=0).fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "train_error = clf.score(X_train, Y_train)\n",
    "test_error = clf.score(X_test, Y_test)\n",
    "\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain accuracy: 1.0\n",
      "\tTest accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_hidden2\n",
    "X_test = X_test_hidden2\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=20, random_state=0).fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "train_error = clf.score(X_train, Y_train)\n",
    "test_error = clf.score(X_test, Y_test)\n",
    "\n",
    "print '\\tTrain accuracy: %s' % str(train_error)\n",
    "print '\\tTest accuracy: %s' % str(test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PCA to plot data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
