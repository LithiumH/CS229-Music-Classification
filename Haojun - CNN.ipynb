{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using CNN\n",
    "\n",
    "Classifying music directly from its midi matrix does not have much grounding. Instead, we are interested in classifying music by first extracting features by using CNNs. In our case, this is done by training a CNN that can accurately predict Jazz vs Classical music and using each level of activations as features for each music. With such a network we are able to \"extract\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mido\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "import StyleNet.midi_util as midi_util\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "We will reuse some code that was use to generate the original [paper](https://arxiv.org/pdf/1708.03535.pdf). Instead of having the velocity matrix as a separate matrix, we will multiply it into our notes matrix and have the label vector to be 0 for classical and 1 for jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midis(base_fpath):\n",
    "    fpaths = []\n",
    "    for (root, dirnames, filenames) in os.walk(base_fpath):\n",
    "        fpaths += [os.path.join(root, filename) for filename in filenames]\n",
    "    return [mido.MidiFile(fpath) for fpath in fpaths]\n",
    "\n",
    "def convert_midis(midis, label):\n",
    "    \"\"\"\n",
    "        midis = a list of MidiFiles we are trying to parse\n",
    "        label = 0 or 1 integer used to generate the label matrix\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for midi in midis:\n",
    "        try:\n",
    "            midi_array, velocity_array = midi_util.midi_to_array_one_hot(midi, 4)\n",
    "        except:\n",
    "            continue\n",
    "        if midi_array.shape[0] < 1024:\n",
    "            continue\n",
    "        midi_notes = midi_array[:1024, ::2] * velocity_array[:1024]\n",
    "        midi_continuation = midi_array[:1024, 1::2]\n",
    "        print(midi_notes.shape, midi_continuation.shape)\n",
    "        X_i = np.dstack((midi_notes, midi_continuation))\n",
    "        X += [X_i]\n",
    "        Y += [[label]]\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_midi = load_midis(\"TPD/classical\")\n",
    "jazz_midi = load_midis(\"TPD/jazz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical, classical_label = convert_midis(classical_midi, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz, jazz_label = convert_midis(jazz_midi, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((classical, jazz))\n",
    "Y = np.vstack((classical_label, jazz_label))\n",
    "assert X.shape[0] == Y.shape[0]\n",
    "inds = np.arange(X.shape[0])\n",
    "np.random.shuffle(inds)\n",
    "X, Y = X[inds], Y[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save(\"matricies/X.npy\", X)\n",
    "np.save(\"matricies/Y.npy\", Y)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The data has already be preprocessed as matricies and we will just straight away load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"matricies/X.npy\")\n",
    "Y = np.load(\"matricies/Y.npy\")\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = ms.train_test_split(X, Y, test_size=0.2, random_state=43)\n",
    "print X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Modeling\n",
    "\n",
    "Now we are interested to see which Neural Network model performs the best in classification so we can use the activations as feature vectors. Here we are experimenting between different Neural Network architectures before settling down on a single NN to use as a feature extractor\n",
    "\n",
    "#### Trial 1\n",
    "\n",
    "First we have a single convolution layer to reduce the amount of weights we will need for the dense layers. then we will have 4 dense layers of size (500, 200, 100, 50) and each dense layer's activation could be used as features. We can explore which level of activation is better as a feature for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(input_shape):\n",
    "    X_input = keras.layers.Input(input_shape)\n",
    "    print(X_input.shape)\n",
    "    X = X_input\n",
    "    X = keras.layers.Conv2D(filters=30, kernel_size=(10, 5), strides=(1, 1), padding='same', \n",
    "                            name='Conv0',\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            data_format=\"channels_last\")(X)\n",
    "    X = keras.layers.Dropout(0.5)(X)    \n",
    "    X = keras.layers.MaxPooling2D(pool_size=(4, 2))(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    print(X.shape)\n",
    "\n",
    "    X = keras.layers.Flatten()(X)\n",
    "    X = keras.layers.Dropout(0.5)(X) \n",
    "    X = keras.layers.Dense(500, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dropout(0.5)(X) \n",
    "    X = keras.layers.Dense(200, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dropout(0.5)(X) \n",
    "    X = keras.layers.Dense(100, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dropout(0.5)(X) \n",
    "    X = keras.layers.Dense(50, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dense(1, activation='sigmoid')(X)\n",
    "    print(X.shape)\n",
    "    model = keras.models.Model(inputs=X_input, outputs=X, name='basic')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m1 = model1(input_shape=(1024, 88, 2))\n",
    "m1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m1.fit(X_train, Y_train, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 5s 46ms/step\n",
      "Loss = 0.2622504429282429\n",
      "Test Accuracy = 0.9252336470880241\n"
     ]
    }
   ],
   "source": [
    "preds = m1.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.save(\"/Users/haojun/Downloads/m1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = keras.models.load_model('/Users/haojun/Downloads/m1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trial 2\n",
    "\n",
    "Trial 2 will have 2 convolution layers and no 1 fully connected layer before the output layer. We can explore whether each of the 3 layer output could be used as feature extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(input_shape):\n",
    "    X_input = keras.layers.Input(input_shape)\n",
    "    print(X_input.shape)\n",
    "    X = X_input\n",
    "    X = keras.layers.Conv2D(filters=10, kernel_size=(10, 5), strides=(1, 1), padding='same', \n",
    "                            name='Conv0',\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            data_format=\"channels_last\")(X)\n",
    "    X = keras.layers.Dropout(0.5)(X)    \n",
    "    X = keras.layers.MaxPooling2D(pool_size=(4, 2))(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = keras.layers.Activation('tanh')(X)\n",
    "    print(X.shape)\n",
    "    \n",
    "    X = keras.layers.Conv2D(filters=50, kernel_size=(5, 3), strides=(1, 1), padding='same', \n",
    "                            name='Conv1',\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            data_format=\"channels_last\")(X)\n",
    "    X = keras.layers.Dropout(0.5)(X)    \n",
    "    X = keras.layers.MaxPooling2D(pool_size=(4, 2))(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = keras.layers.Activation('tanh')(X)\n",
    "    print(X.shape)\n",
    "    \n",
    "    X = keras.layers.Flatten()(X)\n",
    "    X = keras.layers.Dense(500, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dense(1, activation='sigmoid')(X)\n",
    "    print(X.shape)\n",
    "    model = keras.models.Model(inputs=X_input, outputs=X, name='basic')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m2 = model2(input_shape=(1024, 88, 2))\n",
    "m2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 47s 110ms/step - loss: 0.2236 - binary_accuracy: 0.9481\n",
      "Epoch 3/5\n",
      "424/424 [==============================] - 50s 119ms/step - loss: 0.1795 - binary_accuracy: 0.9599\n",
      "Epoch 4/5\n",
      "424/424 [==============================] - 53s 124ms/step - loss: 0.1444 - binary_accuracy: 0.9717\n",
      "Epoch 5/5\n",
      "424/424 [==============================] - 54s 127ms/step - loss: 0.1112 - binary_accuracy: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a9b01e90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.fit(X_train, Y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 4s 37ms/step\n",
      "Loss = 0.5798406311284716\n",
      "Test Accuracy = 0.6728971979328405\n"
     ]
    }
   ],
   "source": [
    "preds2 = m2.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds2[0]))\n",
    "print (\"Test Accuracy = \" + str(preds2[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm very much overfitting this network so I'll attempt to reduce the complexity of the network so I don't overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Network\n",
    "\n",
    "One other thing we are experimenting is whether we can use residual network to have deeper networks since we are attempting to see which activation has the best potential to classify genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Now that we have trained our model and it perform fairly well, we can now attempt to use the weights of the layers within the model and produce the same model but with different layers of outputs. The following code is taken from [StackOverflow](https://stackoverflow.com/questions/41711190/keras-how-to-get-the-output-of-each-layer) with modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments\n",
    "\n",
    "First we define a function f that will output the activations of each layer of our model. The following block of code signifies which model are we going to use for the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually inspect the layers and select the layer that we want to use as feature extractors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1a9b0ee90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1a9b0e4d0>,\n",
       " <keras.layers.core.Dropout at 0x1a9b0e290>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1a9b0e2d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1a9b0e050>,\n",
       " <keras.layers.core.Activation at 0x1a5ff0390>,\n",
       " <keras.layers.core.Flatten at 0x1a9b34050>,\n",
       " <keras.layers.core.Dropout at 0x1a9b34350>,\n",
       " <keras.layers.core.Dense at 0x1a9b34510>,\n",
       " <keras.layers.core.Dropout at 0x1a9b34610>,\n",
       " <keras.layers.core.Dense at 0x1a9b345d0>,\n",
       " <keras.layers.core.Dropout at 0x1a9b34710>,\n",
       " <keras.layers.core.Dense at 0x1a9b34890>,\n",
       " <keras.layers.core.Dropout at 0x1a9b34990>,\n",
       " <keras.layers.core.Dense at 0x1a9b349d0>,\n",
       " <keras.layers.core.Dense at 0x1a9b34ad0>]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [model.layers[layer].output for layer in [5, 8, 10, 12, 14]]\n",
    "f = keras.backend.function([model.input, keras.backend.learning_phase()], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features(X, model, layer_nums):\n",
    "    \"\"\"Extract all the features by taking out the activation output of the layers specified in layer_nums\n",
    "    \n",
    "        X : the data that we are trying to extract features from\n",
    "        model: the model that we are using to extract the features\n",
    "        layer_nums: the layer number that we want to use as feature extractors\n",
    "    \"\"\"\n",
    "    outputs = [model.layers[layer].output for layer in layer_nums]\n",
    "    f = keras.backend.function([model.input, keras.backend.learning_phase()], outputs)\n",
    "    layer_outs = f([X, 0.])\n",
    "    return layer_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layer_outs = extract_all_features(X, model, [5, 8, 10, 12, 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv, dense500, dense200, dense100, dense50 = all_layer_outs\n",
    "conv = conv.reshape(conv.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"/Users/haojun/Downloads/conv.txt\", conv)\n",
    "np.savetxt(\"/Users/haojun/Downloads/dense500.txt\", dense500)\n",
    "np.savetxt(\"/Users/haojun/Downloads/dense200.txt\", dense200)\n",
    "np.savetxt(\"/Users/haojun/Downloads/dense100.txt\", dense100)\n",
    "np.savetxt(\"/Users/haojun/Downloads/dense50.txt\", dense50)\n",
    "np.savetxt(\"/Users/haojun/Downloads/label.txt\", Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Classifications (Exploration Phase)\n",
    "\n",
    "Now we will move on to using classic supervised learning algorithms by using each layer activation output as our feature vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
