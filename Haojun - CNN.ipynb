{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using CNN\n",
    "\n",
    "Classifying music directly from its midi matrix does not have much grounding. Instead, we are interested in classifying music by first extracting features by using CNNs. In our case, this is done by training a CNN that can accurately predict Jazz vs Classical music and using each level of activations as features for each music. With such a network we are able to \"extract\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mido\n",
    "import keras\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "import StyleNet.midi_util as midi_util\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data\n",
    "\n",
    "We will reuse some code that was use to generate the original [paper](https://arxiv.org/pdf/1708.03535.pdf). Instead of having the velocity matrix as a separate matrix, we will multiply it into our notes matrix and have the label vector to be 0 for classical and 1 for jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_midis(base_fpath):\n",
    "    fpaths = []\n",
    "    for (root, dirnames, filenames) in os.walk(base_fpath):\n",
    "        fpaths += [os.path.join(root, filename) for filename in filenames]\n",
    "    return [mido.MidiFile(fpath) for fpath in fpaths]\n",
    "\n",
    "def convert_midis(midis, label):\n",
    "    \"\"\"\n",
    "        midis = a list of MidiFiles we are trying to parse\n",
    "        label = 0 or 1 integer used to generate the label matrix\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for midi in midis:\n",
    "        try:\n",
    "            midi_array, velocity_array = midi_util.midi_to_array_one_hot(midi, 4)\n",
    "        except:\n",
    "            continue\n",
    "        midi_notes = midi_array[:, ::2] * velocity_array\n",
    "        midi_continuation = midi_array[:, 1::2]\n",
    "        print(midi_notes.shape, midi_continuation.shape)\n",
    "        X_i = np.dstack((midi_notes, midi_continuation))\n",
    "        X += [X_i]\n",
    "        Y += [[label]]\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classical, classical_label = convert_midis(load_midis(\"TPD/classical\"), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jazz, jazz_label = convert_midis(load_midis(\"TPD/jazz\"), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((classical, jazz))\n",
    "Y = np.vstack((classical_label, jazz_label))\n",
    "assert X.shape[0] == Y.shape[0]\n",
    "inds = np.arange(X.shape[0])\n",
    "np.random.shuffle(inds)\n",
    "X, Y = X[inds], Y[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((532, 512, 88, 2), (532, 1))\n"
     ]
    }
   ],
   "source": [
    "np.save(\"matricies/X.npy\", X)\n",
    "np.save(\"matricies/Y.npy\", Y)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The data has already be preprocessed as matricies and we will just straight away load them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((532, 512, 88, 2), (532, 1))\n"
     ]
    }
   ],
   "source": [
    "X = np.load(\"matricies/X.npy\")\n",
    "Y = np.load(\"matricies/Y.npy\")\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425, 512, 88, 2) (107, 512, 88, 2) (425, 1) (107, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = ms.train_test_split(X, Y, test_size=0.2, random_state=43)\n",
    "print X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Modeling\n",
    "\n",
    "Now we are interested to see which CNN model performs the best in classification so we can use the activations as feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(input_shape):\n",
    "    X_input = keras.layers.Input(input_shape)\n",
    "    print(X_input.shape)\n",
    "    X = X_input\n",
    "    X = keras.layers.ZeroPadding2D(padding=(8, 0))(X)\n",
    "    X = keras.layers.Conv2D(filters=88, kernel_size=(17, 88), strides=(8, 1),# padding='same', \n",
    "                            name='Conv0',\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "                            data_format=\"channels_last\")(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X)    \n",
    "#     X = keras.layers.MaxPooling2D(pool_size=(2, 1))(X)\n",
    "    X = keras.layers.BatchNormalization(axis = 3, name = 'bn0')(X)\n",
    "    X = keras.layers.Activation('relu')(X)\n",
    "    print(X.shape)\n",
    "\n",
    "#     X = keras.layers.Conv2D(filters=50, kernel_size=(10, 5), strides=(1, 1), padding='same', name='Conv1',\n",
    "#                             kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "#                             bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "#                             data_format=\"channels_last\")(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X) \n",
    "#     X = keras.layers.MaxPooling2D(pool_size=(2, 2))(X)\n",
    "#     X = keras.layers.BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "#     X = keras.layers.Activation('relu')(X)\n",
    "#     print(X.shape)\n",
    "    \n",
    "#     X = keras.layers.Conv2D(filters=50, kernel_size=(5, 3), strides=(1, 1), padding='same', name='Conv2',\n",
    "#                             kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "#                             bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "#                             data_format=\"channels_last\")(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X) \n",
    "#     X = keras.layers.MaxPooling2D(pool_size=(2, 2))(X)\n",
    "#     X = keras.layers.BatchNormalization(axis = 3, name = 'bn2')(X)\n",
    "#     X = keras.layers.Activation('relu')(X)\n",
    "#     print(X.shape)\n",
    "#     X = keras.layers.Conv2D(filters=100, kernel_size=(5, 3), strides=(1, 1), padding='same', name='Conv3',\n",
    "#                             kernel_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "#                             bias_initializer=keras.initializers.glorot_normal(seed=None),\n",
    "#                             data_format=\"channels_last\")(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X) \n",
    "#     X = keras.layers.MaxPooling2D(pool_size=(2, 2))(X)\n",
    "#     X = keras.layers.BatchNormalization(axis = 3, name = 'bn3')(X)\n",
    "#     X = keras.layers.Activation('relu')(X)    \n",
    "#     print(X.shape)\n",
    "\n",
    "    X = keras.layers.Flatten()(X)\n",
    "#     print(X.shape)\n",
    "    X = keras.layers.Dropout(0.5)(X) \n",
    "#     X = keras.layers.Dense(500, activation='sigmoid')(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X) \n",
    "    X = keras.layers.Dense(200, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dropout(0.5)(X) \n",
    "#     X = keras.layers.Dense(100, activation='sigmoid')(X)\n",
    "#     X = keras.layers.Dropout(0.5)(X) \n",
    "    X = keras.layers.Dense(50, activation='sigmoid')(X)\n",
    "    X = keras.layers.Dense(1, activation='sigmoid')(X)\n",
    "#     X = keras.layers.Activation('sigmoid')(X)\n",
    "    print(X.shape)\n",
    "    model = keras.models.Model(inputs=X_input, outputs=X, name='basic')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 512, 88, 2)\n",
      "(?, 64, 1, 88)\n",
      "(?, 1)\n"
     ]
    }
   ],
   "source": [
    "m1 = model1(input_shape=(512, 88, 2))\n",
    "m1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "425/425 [==============================] - 7s 16ms/step - loss: 0.6623 - binary_accuracy: 0.6588\n",
      "Epoch 2/5\n",
      "425/425 [==============================] - 1s 2ms/step - loss: 0.5178 - binary_accuracy: 0.8329\n",
      "Epoch 3/5\n",
      "425/425 [==============================] - 1s 2ms/step - loss: 0.3018 - binary_accuracy: 0.9412\n",
      "Epoch 4/5\n",
      "425/425 [==============================] - 1s 2ms/step - loss: 0.1446 - binary_accuracy: 0.9835\n",
      "Epoch 5/5\n",
      "425/425 [==============================] - 1s 2ms/step - loss: 0.0712 - binary_accuracy: 0.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa145d8d50>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.fit(X_train, Y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 3s 24ms/step\n",
      "Loss = 0.3913348676445328\n",
      "Test Accuracy = 0.85046729250489\n"
     ]
    }
   ],
   "source": [
    "preds = m1.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Network\n",
    "\n",
    "One other thing we are experimenting is whether we can use residual network to have deeper networks since we are attempting to see which activation has the best potential to classify genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Now that we have trained our model and it perform fairly well, we can now attempt to use the weights of the layers within the model and produce the same model but with different layers of outputs. The following code is taken from [StackOverflow](https://stackoverflow.com/questions/41711190/keras-how-to-get-the-output-of-each-layer) with modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments\n",
    "\n",
    "First we define a function f that will output the activations of each layer of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [layer.output for layer in model.layers]\n",
    "f = keras.backend.function([model.input, K.learning_phase()], outputs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [X_train[0]]\n",
    "layer_outs = f([test, 1.])\n",
    "print(layer_outs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
